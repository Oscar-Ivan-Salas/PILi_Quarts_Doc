# üéØ PLAN EJECUTIVO: Completar Migraci√≥n PILI

## üìä ESTADO ACTUAL (23:31 - 28/12/2024)

### ‚úÖ Lo que TENEMOS
1. **Estructura completa** - 19 YAML + carpetas organizadas
2. **C√≥digo existente funcionando** - pili_integrator.py con multi-IA
3. **UniversalSpecialist** - Base modular implementada
4. **LegacyAdapter** - Compatibilidad garantizada

### ‚ùå Lo que FALTA
1. **Copiar l√≥gica multi-IA** de pili_integrator.py a pili/core/orchestrator.py
2. **Integrar orchestrator** con UniversalSpecialist
3. **Probar** que funcione con Gemini
4. **Activar** en chat.py

---

## üöÄ PLAN DE ACCI√ìN (3 PASOS SIMPLES)

### PASO 1: Copiar L√≥gica Multi-IA (30 min)

**Archivo origen:** `pili_integrator.py` (l√≠neas 86-400)

**Archivo destino:** `pili/core/orchestrator.py`

**Qu√© copiar:**
```python
class PILIIntegrator:
    def __init__(self):
        # Inicializaci√≥n de servicios
        self.gemini_service = gemini_service
        self.pili_brain = pili_brain
    
    async def _generar_respuesta_chat(self, mensaje, tipo_flujo, historial, servicio):
        # L√≥gica multi-IA:
        # 1. Intenta Gemini
        # 2. Si falla, usa PILIBrain
        # 3. Si falla, usa plantillas
```

**Resultado:** `pili/core/orchestrator.py` con l√≥gica multi-IA completa

---

### PASO 2: Integrar con UniversalSpecialist (20 min)

**Archivo:** `pili/specialists/universal_specialist.py`

**Cambio:**
```python
# ANTES
def _render_message(self, template_key: str) -> str:
    # Solo retorna template YAML
    return template

# DESPU√âS
def _render_message(self, template_key: str) -> str:
    # Usa orchestrator para respuesta inteligente
    from ..core import get_orchestrator
    orchestrator = get_orchestrator()
    
    # Intenta con IA
    response = await orchestrator.generar_respuesta_chat(...)
    if response:
        return response
    
    # Fallback a template
    return template
```

**Resultado:** UniversalSpecialist usa IA cuando disponible

---

### PASO 3: Activar en Chat.py (5 min)

**Archivo:** `backend/app/routers/chat.py`

**L√≠nea 2894:**
```python
# YA EST√Å HECHO - Solo verificar que est√© as√≠:
from app.services.pili.adapters.legacy_adapter import LocalSpecialistFactory
```

**Resultado:** Chat usa nueva arquitectura con IA

---

## üìã CHECKLIST FINAL

### Antes de activar:
- [ ] Copiar l√≥gica de pili_integrator.py a orchestrator.py
- [ ] Actualizar UniversalSpecialist para usar orchestrator
- [ ] Actualizar LegacyAdapter si es necesario
- [ ] Probar con test simple

### Despu√©s de activar:
- [ ] Reiniciar backend (uvicorn --reload)
- [ ] Probar chat ITSE en frontend
- [ ] Verificar que responde inteligentemente
- [ ] Verificar que genera cotizaci√≥n

---

## üîß C√ìDIGO EXACTO A COPIAR

### De: pili_integrator.py (l√≠neas 196-240)

```python
async def _generar_respuesta_chat(
    self,
    mensaje: str,
    tipo_flujo: str,
    historial: List[Dict],
    servicio: str,
    datos_acumulados: Optional[Dict] = None,
    conversation_state: Optional[Dict] = None
) -> Dict[str, Any]:
    """
    Genera respuesta conversacional con fallback inteligente:
    1. Gemini (si disponible)
    2. PILIBrain (fallback)
    3. Plantillas (√∫ltimo recurso)
    """
    
    # Intentar con Gemini
    if self.gemini_service and self.estado_servicios["gemini"]:
        try:
            respuesta_gemini = await self.gemini_service.generar_respuesta_conversacional(
                mensaje=mensaje,
                tipo_flujo=tipo_flujo,
                historial=historial,
                servicio=servicio
            )
            if respuesta_gemini:
                return {
                    "texto": respuesta_gemini,
                    "agente": "PILI + Gemini",
                    "modo": "ONLINE"
                }
        except Exception as e:
            logger.warning(f"Gemini fall√≥: {e}, usando fallback")
    
    # Fallback a PILIBrain
    if self.pili_brain:
        respuesta_brain = self.pili_brain.generar_respuesta_conversacional(
            mensaje=mensaje,
            servicio=servicio,
            datos_acumulados=datos_acumulados
        )
        return {
            "texto": respuesta_brain,
            "agente": "PILI Brain",
            "modo": "OFFLINE"
        }
    
    # √öltimo recurso: plantilla
    return {
        "texto": "¬øEn qu√© puedo ayudarte?",
        "agente": "PILI",
        "modo": "TEMPLATE"
    }
```

---

## ‚è∞ TIEMPO ESTIMADO TOTAL

- **Paso 1:** 30 minutos (copiar c√≥digo)
- **Paso 2:** 20 minutos (integrar)
- **Paso 3:** 5 minutos (activar)
- **Pruebas:** 15 minutos

**TOTAL:** 70 minutos (1 hora 10 min)

---

## üéØ RESULTADO ESPERADO

**PILI ITSE funcionando con:**
- ‚úÖ Respuestas inteligentes (Gemini)
- ‚úÖ Fallback autom√°tico (PILIBrain)
- ‚úÖ Conversaci√≥n fluida
- ‚úÖ Generaci√≥n de cotizaciones
- ‚úÖ Arquitectura modular
- ‚úÖ 79% menos c√≥digo

---

## üìù NOTAS IMPORTANTES

1. **NO crear c√≥digo nuevo** - Solo copiar lo que ya existe
2. **NO modificar pili_integrator.py** - Dejarlo como backup
3. **Probar antes de commit** - Verificar que funcione
4. **Commit incremental** - Guardar progreso cada paso

---

## üö® SI ALGO FALLA

**Plan B:** Revertir chat.py a usar pili_local_specialists.py

```python
# L√≠nea 2894 de chat.py
from app.services.pili_local_specialists import LocalSpecialistFactory
```

**Esto garantiza que el sistema siga funcionando mientras arreglamos.**

---

## ‚úÖ PR√ìXIMO PASO INMEDIATO

**Ma√±ana empezar con:**
1. Abrir `pili_integrator.py`
2. Copiar m√©todo `_generar_respuesta_chat` completo
3. Pegar en `pili/core/orchestrator.py`
4. Probar

**Tiempo:** 30 minutos
**Riesgo:** Bajo (tenemos backup)
**Beneficio:** Sistema modular funcionando
